{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Classify_Songs_Genres_From_Audio_Data.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMiNHZWHM7CRp7p2MKDPt1o",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Dominika26/classification_tutorials_public/blob/main/Classify_Songs_Genres_From_Audio_Data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "gaRNLPFxDDXb"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import display\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import KFold, cross_val_score\n",
        "\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.linear_model import LogisticRegression"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Read in track metadata with genre labels\n",
        "tracks = pd.read_csv('fma-rock-vs-hiphop.csv')\n",
        "\n",
        "# Read in track metrics with the features\n",
        "echonest_metrics = pd.read_json('echonest-metrics.json', precise_float=True)\n",
        "\n",
        "# Merge the relevant columns of tracks and echonest_metrics\n",
        "echo_tracks = pd.merge(echonest_metrics, tracks[['track_id' , 'genre_top']], how='inner', on='track_id')\n",
        "\n",
        "# Inspect the resultant dataframe\n",
        "echo_tracks.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "57ykQwkBDTMF",
        "outputId": "9835b846-be7f-43b6-9280-08d496fe5680"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 4802 entries, 0 to 4801\n",
            "Data columns (total 10 columns):\n",
            " #   Column            Non-Null Count  Dtype  \n",
            "---  ------            --------------  -----  \n",
            " 0   track_id          4802 non-null   int64  \n",
            " 1   acousticness      4802 non-null   float64\n",
            " 2   danceability      4802 non-null   float64\n",
            " 3   energy            4802 non-null   float64\n",
            " 4   instrumentalness  4802 non-null   float64\n",
            " 5   liveness          4802 non-null   float64\n",
            " 6   speechiness       4802 non-null   float64\n",
            " 7   tempo             4802 non-null   float64\n",
            " 8   valence           4802 non-null   float64\n",
            " 9   genre_top         4802 non-null   object \n",
            "dtypes: float64(8), int64(1), object(1)\n",
            "memory usage: 412.7+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2. Pairwise relationships between continous variables**\n",
        "\n",
        "We typically want to avoid using variables that have strong correlations with each other, hence avoiding feature redundancy for a few reasons:\n",
        "- To keep the model simple and improve interpretability (with many features, we run the risk of overfitting).\n",
        "When our datasets are very large, using fewer features can drastically speed up our computation time.\n",
        "- To get a sense of whether there are any strongly correlated features in our data, we will use built-in functions in the pandas package."
      ],
      "metadata": {
        "id": "Yn8X51GtDohC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# prepare a correlation matrix \n",
        "corr_metrics = echo_tracks.corr()\n",
        "corr_metrics.style.background_gradient()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 331
        },
        "id": "SmFIYPHzDfkc",
        "outputId": "a607ea28-48ff-4db9-987a-bef49b5b000a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pandas.io.formats.style.Styler at 0x7fad5103b550>"
            ],
            "text/html": [
              "<style type=\"text/css\">\n",
              "#T_40efe_row0_col0, #T_40efe_row1_col1, #T_40efe_row2_col2, #T_40efe_row3_col3, #T_40efe_row4_col4, #T_40efe_row5_col5, #T_40efe_row6_col6, #T_40efe_row7_col7, #T_40efe_row8_col8 {\n",
              "  background-color: #023858;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_40efe_row0_col1, #T_40efe_row1_col0, #T_40efe_row1_col3, #T_40efe_row2_col5, #T_40efe_row2_col7, #T_40efe_row4_col2, #T_40efe_row4_col6, #T_40efe_row4_col8, #T_40efe_row6_col4 {\n",
              "  background-color: #fff7fb;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_40efe_row0_col2 {\n",
              "  background-color: #d2d2e7;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_40efe_row0_col3 {\n",
              "  background-color: #b5c4df;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_40efe_row0_col4 {\n",
              "  background-color: #f5eef6;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_40efe_row0_col5 {\n",
              "  background-color: #e9e5f1;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_40efe_row0_col6, #T_40efe_row8_col3 {\n",
              "  background-color: #d1d2e6;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_40efe_row0_col7, #T_40efe_row1_col7 {\n",
              "  background-color: #e1dfed;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_40efe_row0_col8, #T_40efe_row3_col6 {\n",
              "  background-color: #dedcec;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_40efe_row1_col2 {\n",
              "  background-color: #e0dded;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_40efe_row1_col4, #T_40efe_row4_col1 {\n",
              "  background-color: #97b7d7;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_40efe_row1_col5, #T_40efe_row2_col4 {\n",
              "  background-color: #f3edf5;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_40efe_row1_col6, #T_40efe_row6_col1 {\n",
              "  background-color: #b8c6e0;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_40efe_row1_col8 {\n",
              "  background-color: #e2dfee;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_40efe_row2_col0, #T_40efe_row5_col0, #T_40efe_row5_col3 {\n",
              "  background-color: #bdc8e1;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_40efe_row2_col1, #T_40efe_row6_col0, #T_40efe_row7_col0, #T_40efe_row7_col1 {\n",
              "  background-color: #d0d1e6;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_40efe_row2_col3 {\n",
              "  background-color: #fbf3f9;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_40efe_row2_col6 {\n",
              "  background-color: #80aed2;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_40efe_row2_col8 {\n",
              "  background-color: #529bc7;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_40efe_row3_col0, #T_40efe_row7_col3 {\n",
              "  background-color: #a7bddb;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_40efe_row3_col1 {\n",
              "  background-color: #f5eff6;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_40efe_row3_col2, #T_40efe_row7_col2 {\n",
              "  background-color: #fef6fa;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_40efe_row3_col4 {\n",
              "  background-color: #c4cbe3;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_40efe_row3_col5, #T_40efe_row5_col7 {\n",
              "  background-color: #dcdaeb;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_40efe_row3_col7 {\n",
              "  background-color: #adc1dd;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_40efe_row3_col8, #T_40efe_row4_col7 {\n",
              "  background-color: #d9d8ea;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_40efe_row4_col0 {\n",
              "  background-color: #f4eef6;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_40efe_row4_col3 {\n",
              "  background-color: #d2d3e7;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_40efe_row4_col5 {\n",
              "  background-color: #fdf5fa;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_40efe_row5_col1 {\n",
              "  background-color: #ced0e6;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_40efe_row5_col2 {\n",
              "  background-color: #ede8f3;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_40efe_row5_col4, #T_40efe_row6_col7 {\n",
              "  background-color: #dbdaeb;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_40efe_row5_col6 {\n",
              "  background-color: #c0c9e2;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_40efe_row5_col8 {\n",
              "  background-color: #e8e4f0;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_40efe_row6_col2 {\n",
              "  background-color: #93b5d6;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_40efe_row6_col3, #T_40efe_row6_col5 {\n",
              "  background-color: #eae6f1;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_40efe_row6_col8 {\n",
              "  background-color: #bfc9e1;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_40efe_row7_col4 {\n",
              "  background-color: #c5cce3;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_40efe_row7_col5 {\n",
              "  background-color: #f0eaf4;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_40efe_row7_col6 {\n",
              "  background-color: #c8cde4;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_40efe_row7_col8 {\n",
              "  background-color: #d6d6e9;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_40efe_row8_col0 {\n",
              "  background-color: #c6cce3;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_40efe_row8_col1 {\n",
              "  background-color: #cdd0e5;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_40efe_row8_col2 {\n",
              "  background-color: #4c99c5;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_40efe_row8_col4 {\n",
              "  background-color: #efe9f3;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_40efe_row8_col5 {\n",
              "  background-color: #f7f0f7;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_40efe_row8_col6 {\n",
              "  background-color: #a5bddb;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_40efe_row8_col7 {\n",
              "  background-color: #d3d4e7;\n",
              "  color: #000000;\n",
              "}\n",
              "</style>\n",
              "<table id=\"T_40efe_\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th class=\"blank level0\" >&nbsp;</th>\n",
              "      <th class=\"col_heading level0 col0\" >track_id</th>\n",
              "      <th class=\"col_heading level0 col1\" >acousticness</th>\n",
              "      <th class=\"col_heading level0 col2\" >danceability</th>\n",
              "      <th class=\"col_heading level0 col3\" >energy</th>\n",
              "      <th class=\"col_heading level0 col4\" >instrumentalness</th>\n",
              "      <th class=\"col_heading level0 col5\" >liveness</th>\n",
              "      <th class=\"col_heading level0 col6\" >speechiness</th>\n",
              "      <th class=\"col_heading level0 col7\" >tempo</th>\n",
              "      <th class=\"col_heading level0 col8\" >valence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th id=\"T_40efe_level0_row0\" class=\"row_heading level0 row0\" >track_id</th>\n",
              "      <td id=\"T_40efe_row0_col0\" class=\"data row0 col0\" >1.000000</td>\n",
              "      <td id=\"T_40efe_row0_col1\" class=\"data row0 col1\" >-0.372282</td>\n",
              "      <td id=\"T_40efe_row0_col2\" class=\"data row0 col2\" >0.049454</td>\n",
              "      <td id=\"T_40efe_row0_col3\" class=\"data row0 col3\" >0.140703</td>\n",
              "      <td id=\"T_40efe_row0_col4\" class=\"data row0 col4\" >-0.275623</td>\n",
              "      <td id=\"T_40efe_row0_col5\" class=\"data row0 col5\" >0.048231</td>\n",
              "      <td id=\"T_40efe_row0_col6\" class=\"data row0 col6\" >-0.026995</td>\n",
              "      <td id=\"T_40efe_row0_col7\" class=\"data row0 col7\" >-0.025392</td>\n",
              "      <td id=\"T_40efe_row0_col8\" class=\"data row0 col8\" >0.010070</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_40efe_level0_row1\" class=\"row_heading level0 row1\" >acousticness</th>\n",
              "      <td id=\"T_40efe_row1_col0\" class=\"data row1 col0\" >-0.372282</td>\n",
              "      <td id=\"T_40efe_row1_col1\" class=\"data row1 col1\" >1.000000</td>\n",
              "      <td id=\"T_40efe_row1_col2\" class=\"data row1 col2\" >-0.028954</td>\n",
              "      <td id=\"T_40efe_row1_col3\" class=\"data row1 col3\" >-0.281619</td>\n",
              "      <td id=\"T_40efe_row1_col4\" class=\"data row1 col4\" >0.194780</td>\n",
              "      <td id=\"T_40efe_row1_col5\" class=\"data row1 col5\" >-0.019991</td>\n",
              "      <td id=\"T_40efe_row1_col6\" class=\"data row1 col6\" >0.072204</td>\n",
              "      <td id=\"T_40efe_row1_col7\" class=\"data row1 col7\" >-0.026310</td>\n",
              "      <td id=\"T_40efe_row1_col8\" class=\"data row1 col8\" >-0.013841</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_40efe_level0_row2\" class=\"row_heading level0 row2\" >danceability</th>\n",
              "      <td id=\"T_40efe_row2_col0\" class=\"data row2 col0\" >0.049454</td>\n",
              "      <td id=\"T_40efe_row2_col1\" class=\"data row2 col1\" >-0.028954</td>\n",
              "      <td id=\"T_40efe_row2_col2\" class=\"data row2 col2\" >1.000000</td>\n",
              "      <td id=\"T_40efe_row2_col3\" class=\"data row2 col3\" >-0.242032</td>\n",
              "      <td id=\"T_40efe_row2_col4\" class=\"data row2 col4\" >-0.255217</td>\n",
              "      <td id=\"T_40efe_row2_col5\" class=\"data row2 col5\" >-0.106584</td>\n",
              "      <td id=\"T_40efe_row2_col6\" class=\"data row2 col6\" >0.276206</td>\n",
              "      <td id=\"T_40efe_row2_col7\" class=\"data row2 col7\" >-0.242089</td>\n",
              "      <td id=\"T_40efe_row2_col8\" class=\"data row2 col8\" >0.473165</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_40efe_level0_row3\" class=\"row_heading level0 row3\" >energy</th>\n",
              "      <td id=\"T_40efe_row3_col0\" class=\"data row3 col0\" >0.140703</td>\n",
              "      <td id=\"T_40efe_row3_col1\" class=\"data row3 col1\" >-0.281619</td>\n",
              "      <td id=\"T_40efe_row3_col2\" class=\"data row3 col2\" >-0.242032</td>\n",
              "      <td id=\"T_40efe_row3_col3\" class=\"data row3 col3\" >1.000000</td>\n",
              "      <td id=\"T_40efe_row3_col4\" class=\"data row3 col4\" >0.028238</td>\n",
              "      <td id=\"T_40efe_row3_col5\" class=\"data row3 col5\" >0.113331</td>\n",
              "      <td id=\"T_40efe_row3_col6\" class=\"data row3 col6\" >-0.109983</td>\n",
              "      <td id=\"T_40efe_row3_col7\" class=\"data row3 col7\" >0.195227</td>\n",
              "      <td id=\"T_40efe_row3_col8\" class=\"data row3 col8\" >0.038603</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_40efe_level0_row4\" class=\"row_heading level0 row4\" >instrumentalness</th>\n",
              "      <td id=\"T_40efe_row4_col0\" class=\"data row4 col0\" >-0.275623</td>\n",
              "      <td id=\"T_40efe_row4_col1\" class=\"data row4 col1\" >0.194780</td>\n",
              "      <td id=\"T_40efe_row4_col2\" class=\"data row4 col2\" >-0.255217</td>\n",
              "      <td id=\"T_40efe_row4_col3\" class=\"data row4 col3\" >0.028238</td>\n",
              "      <td id=\"T_40efe_row4_col4\" class=\"data row4 col4\" >1.000000</td>\n",
              "      <td id=\"T_40efe_row4_col5\" class=\"data row4 col5\" >-0.091022</td>\n",
              "      <td id=\"T_40efe_row4_col6\" class=\"data row4 col6\" >-0.366762</td>\n",
              "      <td id=\"T_40efe_row4_col7\" class=\"data row4 col7\" >0.022215</td>\n",
              "      <td id=\"T_40efe_row4_col8\" class=\"data row4 col8\" >-0.219967</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_40efe_level0_row5\" class=\"row_heading level0 row5\" >liveness</th>\n",
              "      <td id=\"T_40efe_row5_col0\" class=\"data row5 col0\" >0.048231</td>\n",
              "      <td id=\"T_40efe_row5_col1\" class=\"data row5 col1\" >-0.019991</td>\n",
              "      <td id=\"T_40efe_row5_col2\" class=\"data row5 col2\" >-0.106584</td>\n",
              "      <td id=\"T_40efe_row5_col3\" class=\"data row5 col3\" >0.113331</td>\n",
              "      <td id=\"T_40efe_row5_col4\" class=\"data row5 col4\" >-0.091022</td>\n",
              "      <td id=\"T_40efe_row5_col5\" class=\"data row5 col5\" >1.000000</td>\n",
              "      <td id=\"T_40efe_row5_col6\" class=\"data row5 col6\" >0.041173</td>\n",
              "      <td id=\"T_40efe_row5_col7\" class=\"data row5 col7\" >0.002732</td>\n",
              "      <td id=\"T_40efe_row5_col8\" class=\"data row5 col8\" >-0.045093</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_40efe_level0_row6\" class=\"row_heading level0 row6\" >speechiness</th>\n",
              "      <td id=\"T_40efe_row6_col0\" class=\"data row6 col0\" >-0.026995</td>\n",
              "      <td id=\"T_40efe_row6_col1\" class=\"data row6 col1\" >0.072204</td>\n",
              "      <td id=\"T_40efe_row6_col2\" class=\"data row6 col2\" >0.276206</td>\n",
              "      <td id=\"T_40efe_row6_col3\" class=\"data row6 col3\" >-0.109983</td>\n",
              "      <td id=\"T_40efe_row6_col4\" class=\"data row6 col4\" >-0.366762</td>\n",
              "      <td id=\"T_40efe_row6_col5\" class=\"data row6 col5\" >0.041173</td>\n",
              "      <td id=\"T_40efe_row6_col6\" class=\"data row6 col6\" >1.000000</td>\n",
              "      <td id=\"T_40efe_row6_col7\" class=\"data row6 col7\" >0.008241</td>\n",
              "      <td id=\"T_40efe_row6_col8\" class=\"data row6 col8\" >0.149894</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_40efe_level0_row7\" class=\"row_heading level0 row7\" >tempo</th>\n",
              "      <td id=\"T_40efe_row7_col0\" class=\"data row7 col0\" >-0.025392</td>\n",
              "      <td id=\"T_40efe_row7_col1\" class=\"data row7 col1\" >-0.026310</td>\n",
              "      <td id=\"T_40efe_row7_col2\" class=\"data row7 col2\" >-0.242089</td>\n",
              "      <td id=\"T_40efe_row7_col3\" class=\"data row7 col3\" >0.195227</td>\n",
              "      <td id=\"T_40efe_row7_col4\" class=\"data row7 col4\" >0.022215</td>\n",
              "      <td id=\"T_40efe_row7_col5\" class=\"data row7 col5\" >0.002732</td>\n",
              "      <td id=\"T_40efe_row7_col6\" class=\"data row7 col6\" >0.008241</td>\n",
              "      <td id=\"T_40efe_row7_col7\" class=\"data row7 col7\" >1.000000</td>\n",
              "      <td id=\"T_40efe_row7_col8\" class=\"data row7 col8\" >0.052221</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_40efe_level0_row8\" class=\"row_heading level0 row8\" >valence</th>\n",
              "      <td id=\"T_40efe_row8_col0\" class=\"data row8 col0\" >0.010070</td>\n",
              "      <td id=\"T_40efe_row8_col1\" class=\"data row8 col1\" >-0.013841</td>\n",
              "      <td id=\"T_40efe_row8_col2\" class=\"data row8 col2\" >0.473165</td>\n",
              "      <td id=\"T_40efe_row8_col3\" class=\"data row8 col3\" >0.038603</td>\n",
              "      <td id=\"T_40efe_row8_col4\" class=\"data row8 col4\" >-0.219967</td>\n",
              "      <td id=\"T_40efe_row8_col5\" class=\"data row8 col5\" >-0.045093</td>\n",
              "      <td id=\"T_40efe_row8_col6\" class=\"data row8 col6\" >0.149894</td>\n",
              "      <td id=\"T_40efe_row8_col7\" class=\"data row8 col7\" >0.052221</td>\n",
              "      <td id=\"T_40efe_row8_col8\" class=\"data row8 col8\" >1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "There is not much strong correlation between any features, we do not need to remove any feature from our data "
      ],
      "metadata": {
        "id": "nYq64I1MEjIc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3. Normalizing the feature data**\n",
        "\n",
        "Since we didn’t find any particular strong correlations between our features, we can instead use a common approach to reduce the number of features called principal component analysis (PCA).\n",
        "It is possible that the variance between genres can be explained by just a few features in the dataset. PCA rotates the data along the axis of highest variance, thus allowing us to determine the relative contribution of each feature of our data towards the variance between classes.\n",
        "However, since PCA uses the absolute variance of a feature to rotate the data, a feature with a broader range of values will overpower and bias the algorithm relative to the other features. To avoid this, we must first normalize our data. There are a few methods to do this, but a common way is through standardization, such that all features have a mean = 0 and standard deviation = 1 (the resultant is a z-score)."
      ],
      "metadata": {
        "id": "nf48LatbEuVF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Define our features \n",
        "features = echo_tracks.drop(['track_id', 'genre_top'], axis=1)\n",
        "\n",
        "#define our labels \n",
        "labels = echo_tracks.genre_top\n",
        "\n",
        "#scale the features and set the values to a new variable \n",
        "scaler = StandardScaler()\n",
        "scaled_train_features = scaler.fit_transform(features)"
      ],
      "metadata": {
        "id": "F6S9bGpzEeb_"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#data after standarization\n",
        "pd.DataFrame(scaled_train_features).head(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "yBtqyJKfFpwA",
        "outputId": "df4514af-65da-4dd1-f74c-312ca4ffa101"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          0         1         2         3         4         5         6  \\\n",
              "0 -0.191210  1.304420  0.038316 -1.576494 -0.068755  0.373034  1.153979   \n",
              "1 -0.306036  0.501886  0.788176 -1.599809 -0.545463  2.446155  0.007914   \n",
              "2 -1.204813  1.684139  0.312852 -1.602876  1.229828  0.135130 -0.777317   \n",
              "3 -0.094655  0.417927 -0.265203 -1.553079 -0.607326  2.882707 -0.364657   \n",
              "4  1.361706 -0.985896  1.453323  0.979975 -0.442757 -0.364157 -1.072003   \n",
              "\n",
              "          7  \n",
              "0  0.462287  \n",
              "1 -0.690811  \n",
              "2  0.631077  \n",
              "3  1.652859  \n",
              "4 -1.573102  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-02d1a8aa-962f-4a74-8ddd-c5f86dc9e331\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-0.191210</td>\n",
              "      <td>1.304420</td>\n",
              "      <td>0.038316</td>\n",
              "      <td>-1.576494</td>\n",
              "      <td>-0.068755</td>\n",
              "      <td>0.373034</td>\n",
              "      <td>1.153979</td>\n",
              "      <td>0.462287</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.306036</td>\n",
              "      <td>0.501886</td>\n",
              "      <td>0.788176</td>\n",
              "      <td>-1.599809</td>\n",
              "      <td>-0.545463</td>\n",
              "      <td>2.446155</td>\n",
              "      <td>0.007914</td>\n",
              "      <td>-0.690811</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-1.204813</td>\n",
              "      <td>1.684139</td>\n",
              "      <td>0.312852</td>\n",
              "      <td>-1.602876</td>\n",
              "      <td>1.229828</td>\n",
              "      <td>0.135130</td>\n",
              "      <td>-0.777317</td>\n",
              "      <td>0.631077</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.094655</td>\n",
              "      <td>0.417927</td>\n",
              "      <td>-0.265203</td>\n",
              "      <td>-1.553079</td>\n",
              "      <td>-0.607326</td>\n",
              "      <td>2.882707</td>\n",
              "      <td>-0.364657</td>\n",
              "      <td>1.652859</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.361706</td>\n",
              "      <td>-0.985896</td>\n",
              "      <td>1.453323</td>\n",
              "      <td>0.979975</td>\n",
              "      <td>-0.442757</td>\n",
              "      <td>-0.364157</td>\n",
              "      <td>-1.072003</td>\n",
              "      <td>-1.573102</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-02d1a8aa-962f-4a74-8ddd-c5f86dc9e331')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-02d1a8aa-962f-4a74-8ddd-c5f86dc9e331 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-02d1a8aa-962f-4a74-8ddd-c5f86dc9e331');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4. Prinicipal component analysis on our scaled data**\n",
        "\n",
        "Now that we have preprocessed our data, we are ready to use PCA to determine by how much we can reduce the dimensionality of our data. We can use scree-plots and cumulative explained ratio plots to find the number of components to use in further analyses.\n",
        "\n",
        "Scree-plots display the number of components against the variance explained by each component, sorted in descending order of variance. Scree-plots help us get a better sense of which components explain a sufficient amount of variance in our data. When using scree plots, an ‘elbow’ (a steep drop from one data point to the next) in the plot is typically used to decide on an appropriate cutoff.\n"
      ],
      "metadata": {
        "id": "b9QbCMPaF4CR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pca = PCA()\n",
        "pca.fit(scaled_train_features)\n",
        "exp_variance = pca.explained_variance_ratio_\n",
        "\n",
        "#plot the explained variance\n",
        "fig, ax = plt.subplots()\n",
        "ax.bar(range(pca.n_components_), exp_variance)\n",
        "ax.set_xlabel('Principal component')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "id": "oI7VQPh-Fz3l",
        "outputId": "43fff27b-0345-4862-ca71-15306ff34777"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 0, 'Principal component')"
            ]
          },
          "metadata": {},
          "execution_count": 9
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "There does not appear a clear elbow in this scree plot "
      ],
      "metadata": {
        "id": "zPMyz-IeHKUS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the cumulative explained variance \n",
        "cum_exp_variance = np.cumsum(exp_variance)\n",
        "\n",
        "#plot the cumulative explained variance and draw a dashed line at 0.85\n",
        "fig, ax = plt.subplots()\n",
        "ax.plot(cum_exp_variance)\n",
        "ax.axhline(y=0.85, linestyle='--')\n",
        "\n",
        "# choose the n_components where about 85% of our variance can be explained\n",
        "n_components = 6\n",
        "\n",
        "# Perform PCA with the chosen number of components and project data onto components\n",
        "pca = PCA(n_components, random_state=10)\n",
        "pca.fit(scaled_train_features)\n",
        "pca_projection = pca.transform(scaled_train_features)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "02-s-w6vGtld",
        "outputId": "ac1aab86-2960-43d6-de21-299be7613178"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can use the lower dimensional PCA projection of the data to classify songs into genres. "
      ],
      "metadata": {
        "id": "lwPlCUePHXPH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**5. Splittig data and training a decision tree**"
      ],
      "metadata": {
        "id": "g1Epuf45HrEK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_features, test_features, train_labels, test_labels = train_test_split(\n",
        "    pca_projection, labels, random_state=10)\n",
        "\n",
        "#train our decision tree\n",
        "tree = DecisionTreeClassifier(random_state=10)\n",
        "tree.fit(train_features, train_labels)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C1DgiZibHFx_",
        "outputId": "278c6aa4-3b68-4d87-df1a-c64b2e7337af"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DecisionTreeClassifier(random_state=10)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**6. Compare decision tree to a logistic regression**\n"
      ],
      "metadata": {
        "id": "XahcACjTIz8S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "logreg = LogisticRegression(random_state=10)\n",
        "logreg.fit(train_features, train_labels)\n",
        "pred_labels_logit = logreg.predict(test_features)\n",
        "\n",
        "# Create the classification report for both models\n",
        "from sklearn.metrics import classification_report\n",
        "class_rep_tree = classification_report(test_labels, pred_labels_tree)\n",
        "class_rep_log = classification_report(test_labels, pred_labels_logit)\n",
        "\n",
        "print(\"Decision Tree: \\n\", class_rep_tree)\n",
        "print(\"Logistic Regression: \\n\", class_rep_log)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_wG6f79cIg3m",
        "outputId": "9438f3fc-fcd1-4069-b389-2d96d82b292c"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decision Tree: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "     Hip-Hop       0.60      0.60      0.60       235\n",
            "        Rock       0.90      0.90      0.90       966\n",
            "\n",
            "    accuracy                           0.84      1201\n",
            "   macro avg       0.75      0.75      0.75      1201\n",
            "weighted avg       0.84      0.84      0.84      1201\n",
            "\n",
            "Logistic Regression: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "     Hip-Hop       0.77      0.54      0.64       235\n",
            "        Rock       0.90      0.96      0.93       966\n",
            "\n",
            "    accuracy                           0.88      1201\n",
            "   macro avg       0.83      0.75      0.78      1201\n",
            "weighted avg       0.87      0.88      0.87      1201\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Both models are similiarly well. However we can see that rock song are fairly well classified, but hip-hop songs are misclassidied as rock songs.\n",
        "\n",
        "Well, just by looking at the number of data points we have for each class, we see that we have far more data points for the rock classification than for hip-hop, potentially skewing our model’s ability to distinguish between classes. This also tells us that most of our model’s accuracy is driven by its ability to classify just rock songs, which is less than ideal."
      ],
      "metadata": {
        "id": "SLkiklnFJuHB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**7. Balance our data for greater performance**\n",
        "\n",
        "we only need to account for differences in the sample size of our data points when weighing our classes here, and not relative importance of each class."
      ],
      "metadata": {
        "id": "geJfDP04KwJs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Subset a balanced proportiion of data points \n",
        "hop_only = echo_tracks.loc[echo_tracks['genre_top'] == 'Hip-Hop']\n",
        "rock_only = echo_tracks.loc[echo_tracks['genre_top'] == 'Rock']\n",
        "\n",
        "# subset only the rock songs, and take a sample the same size as there are hip-hop songs\n",
        "rock_only = rock_only.sample(hop_only.shape[0], random_state=10)\n",
        "\n",
        "# concatenate the dataframes hop_only and rock_only\n",
        "rock_hop_bal = pd.concat([rock_only, hop_only])\n",
        "\n",
        "# The features, labels, and pca projection are created for the balanced dataframe\n",
        "features = rock_hop_bal.drop(['genre_top', 'track_id'], axis=1) \n",
        "labels = rock_hop_bal['genre_top']\n",
        "pca_projection = pca.fit_transform(scaler.fit_transform(features))\n",
        "\n",
        "# Redefine the train and test set with the pca_projection from the balanced data\n",
        "train_features, test_features, train_labels, test_labels = train_test_split(\n",
        "    pca_projection, labels, random_state=10)"
      ],
      "metadata": {
        "id": "53rf4UtnJkkR"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**8. Does balancing our dataset improve model bias?**"
      ],
      "metadata": {
        "id": "QNjDgAQ3LlYh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train our data decision tree on the balanced data\n",
        "tree = DecisionTreeClassifier()\n",
        "tree.fit(train_features, train_labels)\n",
        "pred_labels_tree = tree.predict(test_features)\n",
        "\n",
        "# Train our logistic regression on the balanced data\n",
        "logreg = LogisticRegression()\n",
        "logreg.fit(train_features, train_labels)\n",
        "pred_labels_logit = logreg.predict(test_features)\n",
        "\n",
        "# Compare the models\n",
        "print(\"Decision Tree: \\n\", classification_report(test_labels, pred_labels_tree))\n",
        "print(\"Logistic Regression: \\n\", classification_report(test_labels, pred_labels_tree))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o-GHX8fOLjRQ",
        "outputId": "d3527822-f55b-4dd3-a8e9-dafc6d34624e"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decision Tree: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "     Hip-Hop       0.74      0.74      0.74       230\n",
            "        Rock       0.73      0.74      0.74       225\n",
            "\n",
            "    accuracy                           0.74       455\n",
            "   macro avg       0.74      0.74      0.74       455\n",
            "weighted avg       0.74      0.74      0.74       455\n",
            "\n",
            "Logistic Regression: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "     Hip-Hop       0.74      0.74      0.74       230\n",
            "        Rock       0.73      0.74      0.74       225\n",
            "\n",
            "    accuracy                           0.74       455\n",
            "   macro avg       0.74      0.74      0.74       455\n",
            "weighted avg       0.74      0.74      0.74       455\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Balaning our data removed bias towards the more prelevant class. We can also apply cross-validation, this allows us to compare models in more rigorous fashion."
      ],
      "metadata": {
        "id": "vEDOK55xL5sF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**9. Using cross-validation to ealuate our models**\n",
        "\n",
        "Since the way our data is split into train and test sets can impact model performance, CV attempts to split the data multiple ways and test the model on each of the splits. Although there are many different CV methods, all with their own advantages and disadvantages, we will use what’s known as K-fold cross-validation here. K-fold first splits the data into K different, equally sized subsets. Then, it iteratively uses each subset as a test set while using the remainder of the data as train sets. Finally, we can then aggregate the results from each fold for a final model performance score."
      ],
      "metadata": {
        "id": "xXQ6OfuvMLeb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# set up our K-fold cross-validation \n",
        "kf = KFold(n_splits=10)\n",
        "\n",
        "tree = DecisionTreeClassifier(random_state=10)\n",
        "logreg = LogisticRegression(random_state=10)\n",
        "\n",
        "# train our model using KFold cv \n",
        "tree_score = cross_val_score(tree,pca_projection, labels, cv=kf)\n",
        "logit_score = cross_val_score(logreg,pca_projection, labels, cv=kf)\n",
        "\n",
        "# Print the mean of each array of scores\n",
        "print(\"Decision Tree:\", tree_score, \"Logistic Regression:\", logit_score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e1DIxzvgL2lx",
        "outputId": "0324285f-a509-46f5-85bc-7404cc2e46f9"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decision Tree: [0.6978022  0.72527473 0.78021978 0.70879121 0.71428571 0.75274725\n",
            " 0.76923077 0.71978022 0.78021978 0.84065934] Logistic Regression: [0.76923077 0.80769231 0.82417582 0.76923077 0.76923077 0.78021978\n",
            " 0.77472527 0.74175824 0.7967033  0.7967033 ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, that we have performed k fold cross-validation on our dataset, we can be pretty sure that our model will generalize 72% of the times on the future unseen data points. "
      ],
      "metadata": {
        "id": "RCKzRtHPM7Fc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Hg9ZqoUIM28T"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}